{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some urls to extract dialogues from\n",
    "urls = [\"https://imsdb.com/scripts/A-Most-Violent-Year.html\", \"https://imsdb.com/scripts/Absolute-Power.html\",\n",
    "\"https://imsdb.com/scripts/Reservoir-Dogs.html\",\n",
    "\"https://imsdb.com/scripts/Natural-Born-Killers.html\", \"https://imsdb.com/scripts/Jackie-Brown.html\", \n",
    " \"https://imsdb.com/scripts/Four-Rooms.html\", \n",
    "\"https://imsdb.com/scripts/Catch-Me-If-You-Can.html\", \"https://imsdb.com/scripts/Ex-Machina.html\", \n",
    "\"https://imsdb.com/scripts/Heist.html\", \"https://imsdb.com/scripts/Invictus.html\", \n",
    "\"https://imsdb.com/scripts/Only-God-Forgives.html\", \"https://imsdb.com/scripts/Passengers.html\", \n",
    "\"https://imsdb.com/scripts/Quantum-Project.html\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Auxiliary functions and Data Structures to deal with the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(input_text):\n",
    "    \"\"\"\n",
    "    Cleans a given line of unnecessary characters\n",
    "    \"\"\"\n",
    "    clean_line= input_text.text\n",
    "\n",
    "    # find a break in the line and remove the following\n",
    "    rm_index = clean_line.find(\"\\r\\n\\r\\n\")\n",
    "    if rm_index != -1:\n",
    "        clean_line = clean_line[0:rm_index]\n",
    "\n",
    "    # find and remove parenthesis and what it is inside\n",
    "    rm_index1 = clean_line.find(\"(\")\n",
    "    rm_index2 = clean_line.find(\")\")\n",
    "    if rm_index1 != -1:\n",
    "        clean_line = clean_line[0:rm_index1] + clean_line[rm_index2+1:]\n",
    "\n",
    "\n",
    "    # remove special characters\n",
    "    clean_line = clean_line.strip()\n",
    "    clean_line= clean_line.replace(\"\\r\", \"\")\n",
    "    clean_line = clean_line.replace(\"\\n\", \" \")\n",
    "    clean_line = re.sub(\"\\s+\", \" \", clean_line)\n",
    "\n",
    "\n",
    "    return clean_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appropiate_sent(text):\n",
    "    \"\"\"\n",
    "    If It is not empty or does not have numbers innit\n",
    "    \"\"\"\n",
    "    appropiate = True\n",
    "\n",
    "    if any(map(str.isdigit, text)) or text ==\"\" :\n",
    "        appropiate = False\n",
    "\n",
    "    return appropiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "\n",
    "    def __init__(self, who, what):\n",
    "        self.who = who\n",
    "        self.what = what\n",
    "\n",
    "    def print_sentence(self):\n",
    "        text = self.who + \": \" + self.what\n",
    "\n",
    "        return text\n",
    "    \n",
    "class Dialogue:\n",
    "\n",
    "    def __init__(self, sentences):\n",
    "        self.num_sentences = len(sentences)\n",
    "        self.sentences = sentences\n",
    "        self.speakers = list(set([sent.who for sent in sentences]))\n",
    "        self.num_speakers = len(self.speakers)\n",
    "        \n",
    "    def print_dialogue(self):\n",
    "        text = \"\"\n",
    "        for sent in self.sentences:\n",
    "            text += sent.print_sentence() + \"\\n\"\n",
    "\n",
    "        print(text)\n",
    "        return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_phrase(phrase):\n",
    "    \"\"\"\n",
    "    checks if the phrase is smaller than 20 words and arranges it if not.\n",
    "    \"\"\"\n",
    "\n",
    "    aux_list = phrase.split()\n",
    "    \n",
    "    if len(aux_list) <20:\n",
    "        return phrase\n",
    "    else:\n",
    "        aux_list = re.split(\"(\\? |\\.|\\!|;)\",phrase)\n",
    "        final_phrase = \"\"\n",
    "        num_words = 0\n",
    "        \n",
    "        while aux_list !=[]:\n",
    "            last_item = aux_list.pop()\n",
    "            len_last_item = len(last_item.split())\n",
    "            if len_last_item < (20 - num_words):\n",
    "                final_phrase = last_item + \" \" + final_phrase\n",
    "            num_words += len_last_item\n",
    "\n",
    "        final_phrase=final_phrase.replace(\".  \", \"\", 1)\n",
    "        final_phrase = final_phrase.replace(\" .\", \".\")\n",
    "        return final_phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Function that gathers the past functions and creates a text file containing the dialogues of a movie passed as an url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dialogue(url):\n",
    "    \n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "    except:\n",
    "        print(\"Error al abrir la URL\")\n",
    "\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    # Buscamos el <div> correspondiente y sacamos su contenido:\n",
    "    content = soup.find('pre')\n",
    "\n",
    "    # Extract by content EACH HTML TOPIC\n",
    "    all = [x for x in content]\n",
    "    if len(all) == 1:\n",
    "        content = content.find('pre')\n",
    "        all = [x for x in content]\n",
    "\n",
    "    # PARSING OF EACH HTML TOPIC\n",
    "    parsed_doc = []\n",
    "    for line in all:\n",
    "\n",
    "        # We found out that the sentences that start by \" \" are the dialogues\n",
    "        if line.text.startswith(\" \"):\n",
    "            c_line = clean_line(line)\n",
    "            parsed_doc.append(c_line)\n",
    "        # if it is not a dialogue, it is a scene change\n",
    "        else:\n",
    "            parsed_doc.append(\"-------\")\n",
    "\n",
    "\n",
    "    # CLEANING THE EACH TOPIC\n",
    "    cleaned_doc = [\"-------\"]\n",
    "    i= 0\n",
    "    while i < len(parsed_doc) - 1:\n",
    "\n",
    "        # 2 case: it starts with -\n",
    "        if parsed_doc[i].__contains__(\"-\"):\n",
    "            if not cleaned_doc[-1].__contains__(\"-\"):\n",
    "                cleaned_doc.append(parsed_doc[i])\n",
    "\n",
    "        # 1: if it is not alpha. Numbers are not welcomed\n",
    "        elif appropiate_sent(parsed_doc[i]):\n",
    "            cleaned_doc.append(parsed_doc[i])\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        i+=1\n",
    "    \n",
    "    # STRUCTURING THE DIALOGUES into speaker and what\n",
    "    structured_doc = []\n",
    "    i= 0\n",
    "    dialogue_sentences = []\n",
    "    while i < (len(cleaned_doc) - 1):\n",
    "        \n",
    "        if cleaned_doc[i].isupper() and not cleaned_doc[i+1].isupper() and not cleaned_doc[i+1].__contains__(\"--\"):\n",
    "            sent = Sentence(who=cleaned_doc[i], what=cleaned_doc[i+1])\n",
    "            dialogue_sentences.append(sent)\n",
    "            i+=2\n",
    "        \n",
    "        elif dialogue_sentences != []:\n",
    "            dialogue = Dialogue(dialogue_sentences)\n",
    "            structured_doc.append(dialogue)\n",
    "            \n",
    "            dialogue_sentences = []\n",
    "            i+=1\n",
    "        else:\n",
    "\n",
    "            i+=1\n",
    "\n",
    "    # WRITING TO TEXT FILE IF IT FITS THE STANDARD (20 words)\n",
    "    if structured_doc !=[]:\n",
    "        name_file = re.findall(\"scripts/(.*)\\.html\", url)[0] + \".txt\"\n",
    "        f = open(name_file, \"w\", encoding = \"utf-8\")\n",
    "\n",
    "        for dialogue in structured_doc:\n",
    "            if dialogue.num_speakers ==2 and dialogue.num_sentences>1:\n",
    "                question = check_phrase(dialogue.sentences[0].what)\n",
    "                question_bool = False if question == \"\" else True\n",
    "                for i in range(1, dialogue.num_sentences -1):\n",
    "                    answer = check_phrase(dialogue.sentences[i].what)\n",
    "                    answer_bool = False if answer == \"\" else True\n",
    "\n",
    "                    if question_bool and answer_bool:\n",
    "                        f.write(question + \"\\t\" + answer + \"\\n\")\n",
    "                    \n",
    "                    question_bool = answer_bool\n",
    "                    question = answer\n",
    "        f.close()\n",
    "\n",
    "    return structured_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extracting dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    extract_dialogue(url)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81d571fb6155e9824af6ce79a9385db6d1fad418e547fb1d894ef617504fe823"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
